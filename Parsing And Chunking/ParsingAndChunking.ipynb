{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "ParsingAndChunking.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lbKhSI2ejnF"
      },
      "source": [
        "# Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-06-19T17:46:59.210913Z",
          "start_time": "2018-06-19T17:46:55.793571Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHBus5P8ejnK",
        "outputId": "713e984e-6161-45ac-b57b-83a3787173c1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('ghostscript')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "S -> NP VP\n",
        "PP -> P NP\n",
        "NP -> Det N | Det N PP | 'I'\n",
        "VP -> V NP | VP PP\n",
        "Det -> 'an' | 'my'\n",
        "N -> 'elephant' | 'pajamas'\n",
        "V -> 'shot'\n",
        "P -> 'in'\n",
        "\"\"\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Error loading ghostscript: Package 'ghostscript' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMgpLDuFejnM"
      },
      "source": [
        "NLTK offers a number of different parser generators. See http://www.nltk.org/book/ch08.html for more options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-06-19T17:46:59.235916Z",
          "start_time": "2018-06-19T17:46:59.212913Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1QT-Or9ejnN",
        "outputId": "a9e85137-3747-44c3-87ed-9df5608f3e18"
      },
      "source": [
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "sent = nltk.word_tokenize('I shot an elephant in my pajamas')\n",
        "\n",
        "parse_trees = list(parser.parse(sent))\n",
        "for tree in parse_trees:\n",
        "    print(tree)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (VP (V shot) (NP (Det an) (N elephant)))\n",
            "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (V shot)\n",
            "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-fkZeziejnP"
      },
      "source": [
        "## An example with recursion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-06-19T17:47:42.554247Z",
          "start_time": "2018-06-19T17:47:42.543246Z"
        },
        "collapsed": true,
        "id": "nua86PRmejnQ"
      },
      "source": [
        "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
        "  S  -> NP VP\n",
        "  NP -> Det Nom | PropN\n",
        "  Nom -> Adj Nom | N\n",
        "  VP -> V Adj | V NP | V S | V NP PP\n",
        "  PP -> P NP\n",
        "  PropN -> 'Buster' | 'Chatterer' | 'Joe'\n",
        "  Det -> 'the' | 'a'\n",
        "  N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log'\n",
        "  Adj  -> 'angry' | 'frightened' |  'little' | 'tall'\n",
        "  V ->  'chased'  | 'saw' | 'said' | 'thought' | 'was' | 'put'\n",
        "  P -> 'on'\n",
        "  \"\"\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-06-19T17:48:09.268918Z",
          "start_time": "2018-06-19T17:47:56.673659Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ3YijpJejnR",
        "outputId": "a5ee236f-ac52-4c27-d081-c22eba5dad8b"
      },
      "source": [
        "parser = nltk.ChartParser(grammar2)\n",
        "\n",
        "sent1 = nltk.word_tokenize('the angry bear chased the frightened little squirrel')\n",
        "sent2 = nltk.word_tokenize('Chatterer said Buster thought the tree was tall')\n",
        "\n",
        "parse_trees = list(parser.parse(sent2))\n",
        "for tree in parse_trees:\n",
        "    print(tree)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (PropN Chatterer))\n",
            "  (VP\n",
            "    (V said)\n",
            "    (S\n",
            "      (NP (PropN Buster))\n",
            "      (VP\n",
            "        (V thought)\n",
            "        (S (NP (Det the) (Nom (N tree))) (VP (V was) (Adj tall)))))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySnxfPcbejnT"
      },
      "source": [
        "# Chunking\n",
        "\n",
        "Difference to Parsing:\n",
        "\n",
        "* No recursion possible\n",
        "* Maximum depth of parse trees\n",
        "* Sentence is not required to be covered by one tree. The algorithm will find partial structures ('chunks') in the sentence.\n",
        "\n",
        "Let us try to write a chunker for noun phrases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-06-19T17:48:21.269118Z",
          "start_time": "2018-06-19T17:48:21.260117Z"
        },
        "id": "DgJ4LYIUejnT"
      },
      "source": [
        "grammar = r\"\"\"\n",
        "   NP: {<DT>?(<JJ>)*<NN.*>}\n",
        "\"\"\"\n",
        "\n",
        "cp = nltk.RegexpParser(grammar)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-06-19T17:48:27.729764Z",
          "start_time": "2018-06-19T17:48:22.641255Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvaGVJYPejnU",
        "outputId": "a875cc9f-7524-4539-bc1a-01c74fae33a6"
      },
      "source": [
        "tagged_tokens = nltk.pos_tag(sent1)\n",
        "\n",
        "tree = cp.parse(tagged_tokens)\n",
        "print(tree)\n",
        "#tree.draw()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP the/DT angry/JJ bear/NN)\n",
            "  chased/VBD\n",
            "  (NP the/DT frightened/JJ little/JJ squirrel/NN))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsK2RnpRejnU",
        "outputId": "2647bdd3-4cea-48a5-e270-8f9972f684df"
      },
      "source": [
        "for node in tree:\n",
        "    if isinstance(node, nltk.tree.Tree):               \n",
        "        if node.label() == 'NP':\n",
        "            NP =  node.leaves()\n",
        "            print(NP)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 'DT'), ('angry', 'JJ'), ('bear', 'NN')]\n",
            "[('the', 'DT'), ('frightened', 'JJ'), ('little', 'JJ'), ('squirrel', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T_pbLNoejnU",
        "outputId": "51f06fda-ce2c-43e9-c804-c7a0e1395aca"
      },
      "source": [
        "tagged_tokens = nltk.pos_tag(sent2)\n",
        "\n",
        "tree = cp.parse(tagged_tokens)\n",
        "print(tree)\n",
        "#tree.draw()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP Chatterer/NNP)\n",
            "  said/VBD\n",
            "  (NP Buster/NNP)\n",
            "  thought/VBD\n",
            "  (NP the/DT tree/NN)\n",
            "  was/VBD\n",
            "  tall/JJ)\n"
          ]
        }
      ]
    }
  ]
}