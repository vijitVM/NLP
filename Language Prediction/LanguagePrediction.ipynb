{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LanguagePrediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaXivMXoVojm"
      },
      "source": [
        "# Language Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90tX5XiUVqlk"
      },
      "source": [
        "Whenever we want to work with textual data, there is the need to identify the language it is written in. There is no difference if we are spellchecking a text, building a search index or search for the names of people, each of these tasks is always language dependent. Sometimes you can find metadata for the texts, where the language is mentioned. But this is not always the case and sometimes wrong. In those cases it is often easier to just detect the language.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsTJvKLLWUzl"
      },
      "source": [
        "## 1 Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-mwbEq4WefY"
      },
      "source": [
        "What exactly is the task?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImxHTsRAWhw8"
      },
      "source": [
        "### 1.1 Number of Languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF_Z_V20WfNl"
      },
      "source": [
        "The task is easier if we only have to predict between two languages, instead of 3000. In a lot of practical cases we do have to choose from a couple of languages. For example if we collect Social Media Texts about a \"german topic\" or from a German Site, we can be very certain that the language is either German or English. This also applies to abstracts collected from the catalogue of a german library. \n",
        "\n",
        "In the following section we want to select from a small number of Western European languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJPR64o-WpF8"
      },
      "source": [
        "### 1.2 Text encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEACqMuZWrVd"
      },
      "source": [
        "Worst case scenario: We dont even know the encoding a file is in. We are reading bits and bytes, we don't know whether we should convert it to ASCII, UTF8 or Latin2. In this cases we have to predict also the encoding, but we neglect this problem for this exercise and assume that all texts we read are coded in UTF8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-7FUicvWt1P"
      },
      "source": [
        "## Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULCgUV3uW0nE"
      },
      "source": [
        "A simple algorthm would be: How many typical/frequent German words do we find in a given text. First of all the text needs to have a sufficiant length to make precise predictions, as some words belong to different languages.\n",
        "Another frequently suggested approach is to count the occurance of stopwords, as stopwords are frequent (stopword lists are also easily accessible). This approach doesn't work with short texts. Words like 'de' and 'en' are for example part of the French and Dutch language/stopword list. Such double occurences are frequent, as stopwords are usually just one or two syllables long and the nummer of possible syllables is not infinite.\n",
        "\n",
        "A book title such as:\n",
        "\n",
        "*De kleine prins en de grote drakejacht*\n",
        "\n",
        "could be French or Dutch, if you only look at the stopwords. But someone who is familiar with both languages knows that it is a Dutch phrase.\n",
        "\n",
        "The best results are achieved when we are using character distributions as a feature and not word occurences.\n",
        "In English, the letter y is much more frequent then in German. On the other hand, German has characters (Umlaute) that do not appear in English at all. Even better are combinations of 2 or 3 letters, so called bi- and tri-gramms. We can also combine characters, bi- and trigramms as described in this paper:\n",
        "\n",
        "Cavnar, W.B., Trenkle, J.M.: *N-gram-based text categorization*. In: Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval. pp. 161-175 (1994) http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.21.3248&rep=rep1&type=pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nb32zZcW2Sk"
      },
      "source": [
        "### 2.1 Extraction of n-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxqXw_XmW5z9"
      },
      "source": [
        "The following function extracts ngrams from a string:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:48.903804Z",
          "start_time": "2018-04-11T00:35:48.897804Z"
        },
        "collapsed": true,
        "id": "WGg9ZStPUAv2"
      },
      "source": [
        "def ngram(string,n):\n",
        "    liste = []\n",
        "    if n < len(string):\n",
        "        for p in range(len(string) - n + 1) :\n",
        "            tg = string[p:p+n]\n",
        "            liste.append(tg)\n",
        "    return liste"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXkrXEoW-RW"
      },
      "source": [
        "Testing the fuction:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:48.911804Z",
          "start_time": "2018-04-11T00:35:48.907804Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JTKbzHsU71F",
        "outputId": "a9678f56-6ed8-4303-dbc7-54964876fc74"
      },
      "source": [
        "text = \"Die Verfasserin unternimmt es in diesem Buche, die Geschichte des Kautschuks in Menschenschicksalen zu erzählen.\"\n",
        "trigramme = ngram(text,3)\n",
        "print(trigramme)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Die', 'ie ', 'e V', ' Ve', 'Ver', 'erf', 'rfa', 'fas', 'ass', 'sse', 'ser', 'eri', 'rin', 'in ', 'n u', ' un', 'unt', 'nte', 'ter', 'ern', 'rni', 'nim', 'imm', 'mmt', 'mt ', 't e', ' es', 'es ', 's i', ' in', 'in ', 'n d', ' di', 'die', 'ies', 'ese', 'sem', 'em ', 'm B', ' Bu', 'Buc', 'uch', 'che', 'he,', 'e, ', ', d', ' di', 'die', 'ie ', 'e G', ' Ge', 'Ges', 'esc', 'sch', 'chi', 'hic', 'ich', 'cht', 'hte', 'te ', 'e d', ' de', 'des', 'es ', 's K', ' Ka', 'Kau', 'aut', 'uts', 'tsc', 'sch', 'chu', 'huk', 'uks', 'ks ', 's i', ' in', 'in ', 'n M', ' Me', 'Men', 'ens', 'nsc', 'sch', 'che', 'hen', 'ens', 'nsc', 'sch', 'chi', 'hic', 'ick', 'cks', 'ksa', 'sal', 'ale', 'len', 'en ', 'n z', ' zu', 'zu ', 'u e', ' er', 'erz', 'rzä', 'zäh', 'ähl', 'hle', 'len', 'en.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGt6ilPkXL9H"
      },
      "source": [
        "According to Cavnar et al. the best results are achieved by combining mono-, bi- and trigramms, so we write a functions that does exectly this (for  1≤n<4 ).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:48.918804Z",
          "start_time": "2018-04-11T00:35:48.915804Z"
        },
        "collapsed": true,
        "id": "zKc24jS8U-SE"
      },
      "source": [
        "def xgram(string):\n",
        "    return [w for n in range(1,4) for w in ngram(string.lower(),n)]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:48.926804Z",
          "start_time": "2018-04-11T00:35:48.921804Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zqnTIkMU_Uk",
        "outputId": "208ffd62-fb5f-4483-b5b1-0ef906f5d91d"
      },
      "source": [
        "xgramme = xgram(text)\n",
        "print(xgramme)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['d', 'i', 'e', ' ', 'v', 'e', 'r', 'f', 'a', 's', 's', 'e', 'r', 'i', 'n', ' ', 'u', 'n', 't', 'e', 'r', 'n', 'i', 'm', 'm', 't', ' ', 'e', 's', ' ', 'i', 'n', ' ', 'd', 'i', 'e', 's', 'e', 'm', ' ', 'b', 'u', 'c', 'h', 'e', ',', ' ', 'd', 'i', 'e', ' ', 'g', 'e', 's', 'c', 'h', 'i', 'c', 'h', 't', 'e', ' ', 'd', 'e', 's', ' ', 'k', 'a', 'u', 't', 's', 'c', 'h', 'u', 'k', 's', ' ', 'i', 'n', ' ', 'm', 'e', 'n', 's', 'c', 'h', 'e', 'n', 's', 'c', 'h', 'i', 'c', 'k', 's', 'a', 'l', 'e', 'n', ' ', 'z', 'u', ' ', 'e', 'r', 'z', 'ä', 'h', 'l', 'e', 'n', '.', 'di', 'ie', 'e ', ' v', 've', 'er', 'rf', 'fa', 'as', 'ss', 'se', 'er', 'ri', 'in', 'n ', ' u', 'un', 'nt', 'te', 'er', 'rn', 'ni', 'im', 'mm', 'mt', 't ', ' e', 'es', 's ', ' i', 'in', 'n ', ' d', 'di', 'ie', 'es', 'se', 'em', 'm ', ' b', 'bu', 'uc', 'ch', 'he', 'e,', ', ', ' d', 'di', 'ie', 'e ', ' g', 'ge', 'es', 'sc', 'ch', 'hi', 'ic', 'ch', 'ht', 'te', 'e ', ' d', 'de', 'es', 's ', ' k', 'ka', 'au', 'ut', 'ts', 'sc', 'ch', 'hu', 'uk', 'ks', 's ', ' i', 'in', 'n ', ' m', 'me', 'en', 'ns', 'sc', 'ch', 'he', 'en', 'ns', 'sc', 'ch', 'hi', 'ic', 'ck', 'ks', 'sa', 'al', 'le', 'en', 'n ', ' z', 'zu', 'u ', ' e', 'er', 'rz', 'zä', 'äh', 'hl', 'le', 'en', 'n.', 'die', 'ie ', 'e v', ' ve', 'ver', 'erf', 'rfa', 'fas', 'ass', 'sse', 'ser', 'eri', 'rin', 'in ', 'n u', ' un', 'unt', 'nte', 'ter', 'ern', 'rni', 'nim', 'imm', 'mmt', 'mt ', 't e', ' es', 'es ', 's i', ' in', 'in ', 'n d', ' di', 'die', 'ies', 'ese', 'sem', 'em ', 'm b', ' bu', 'buc', 'uch', 'che', 'he,', 'e, ', ', d', ' di', 'die', 'ie ', 'e g', ' ge', 'ges', 'esc', 'sch', 'chi', 'hic', 'ich', 'cht', 'hte', 'te ', 'e d', ' de', 'des', 'es ', 's k', ' ka', 'kau', 'aut', 'uts', 'tsc', 'sch', 'chu', 'huk', 'uks', 'ks ', 's i', ' in', 'in ', 'n m', ' me', 'men', 'ens', 'nsc', 'sch', 'che', 'hen', 'ens', 'nsc', 'sch', 'chi', 'hic', 'ick', 'cks', 'ksa', 'sal', 'ale', 'len', 'en ', 'n z', ' zu', 'zu ', 'u e', ' er', 'erz', 'rzä', 'zäh', 'ähl', 'hle', 'len', 'en.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4ZFdMVIXWNU"
      },
      "source": [
        "## 2.1 Language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddw85W3ZXYQU"
      },
      "source": [
        "A **model** for a language is a set of such n-gramms and their probabilities. In the following, a model is represented as a python dictionary.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:48.941804Z",
          "start_time": "2018-04-11T00:35:48.934804Z"
        },
        "collapsed": true,
        "id": "vSH5ryVOVAzc"
      },
      "source": [
        "def buildmodel(text):\n",
        "    model = {}\n",
        "\n",
        "    xgramme = xgram(text)\n",
        "    nr_of_ngs = len(xgramme)\n",
        "\n",
        "    for w in xgramme:\n",
        "        f = 1 + model.get(w,0)\n",
        "        model[w] = f\n",
        "    \n",
        "    for w in model:\n",
        "        model[w] = float(model[w]) / float(nr_of_ngs)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPX0ELsZXbXN"
      },
      "source": [
        "Testing the function an printing the result:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:48.949804Z",
          "start_time": "2018-04-11T00:35:48.943804Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbKZNZmAVBwE",
        "outputId": "7b6acd51-4d71-4899-9680-3fb167e49450"
      },
      "source": [
        "model = buildmodel(text)\n",
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'d': 0.012012012012012012, 'i': 0.02702702702702703, 'e': 0.05105105105105105, ' ': 0.042042042042042045, 'v': 0.003003003003003003, 'r': 0.012012012012012012, 'f': 0.003003003003003003, 'a': 0.009009009009009009, 's': 0.03303303303303303, 'n': 0.02702702702702703, 'u': 0.015015015015015015, 't': 0.012012012012012012, 'm': 0.012012012012012012, 'b': 0.003003003003003003, 'c': 0.021021021021021023, 'h': 0.021021021021021023, ',': 0.003003003003003003, 'g': 0.003003003003003003, 'k': 0.009009009009009009, 'l': 0.006006006006006006, 'z': 0.006006006006006006, 'ä': 0.003003003003003003, '.': 0.003003003003003003, 'di': 0.009009009009009009, 'ie': 0.009009009009009009, 'e ': 0.009009009009009009, ' v': 0.003003003003003003, 've': 0.003003003003003003, 'er': 0.012012012012012012, 'rf': 0.003003003003003003, 'fa': 0.003003003003003003, 'as': 0.003003003003003003, 'ss': 0.003003003003003003, 'se': 0.006006006006006006, 'ri': 0.003003003003003003, 'in': 0.009009009009009009, 'n ': 0.012012012012012012, ' u': 0.003003003003003003, 'un': 0.003003003003003003, 'nt': 0.003003003003003003, 'te': 0.006006006006006006, 'rn': 0.003003003003003003, 'ni': 0.003003003003003003, 'im': 0.003003003003003003, 'mm': 0.003003003003003003, 'mt': 0.003003003003003003, 't ': 0.003003003003003003, ' e': 0.006006006006006006, 'es': 0.012012012012012012, 's ': 0.009009009009009009, ' i': 0.006006006006006006, ' d': 0.009009009009009009, 'em': 0.003003003003003003, 'm ': 0.003003003003003003, ' b': 0.003003003003003003, 'bu': 0.003003003003003003, 'uc': 0.003003003003003003, 'ch': 0.018018018018018018, 'he': 0.006006006006006006, 'e,': 0.003003003003003003, ', ': 0.003003003003003003, ' g': 0.003003003003003003, 'ge': 0.003003003003003003, 'sc': 0.012012012012012012, 'hi': 0.006006006006006006, 'ic': 0.006006006006006006, 'ht': 0.003003003003003003, 'de': 0.003003003003003003, ' k': 0.003003003003003003, 'ka': 0.003003003003003003, 'au': 0.003003003003003003, 'ut': 0.003003003003003003, 'ts': 0.003003003003003003, 'hu': 0.003003003003003003, 'uk': 0.003003003003003003, 'ks': 0.006006006006006006, ' m': 0.003003003003003003, 'me': 0.003003003003003003, 'en': 0.012012012012012012, 'ns': 0.006006006006006006, 'ck': 0.003003003003003003, 'sa': 0.003003003003003003, 'al': 0.003003003003003003, 'le': 0.006006006006006006, ' z': 0.003003003003003003, 'zu': 0.003003003003003003, 'u ': 0.003003003003003003, 'rz': 0.003003003003003003, 'zä': 0.003003003003003003, 'äh': 0.003003003003003003, 'hl': 0.003003003003003003, 'n.': 0.003003003003003003, 'die': 0.009009009009009009, 'ie ': 0.006006006006006006, 'e v': 0.003003003003003003, ' ve': 0.003003003003003003, 'ver': 0.003003003003003003, 'erf': 0.003003003003003003, 'rfa': 0.003003003003003003, 'fas': 0.003003003003003003, 'ass': 0.003003003003003003, 'sse': 0.003003003003003003, 'ser': 0.003003003003003003, 'eri': 0.003003003003003003, 'rin': 0.003003003003003003, 'in ': 0.009009009009009009, 'n u': 0.003003003003003003, ' un': 0.003003003003003003, 'unt': 0.003003003003003003, 'nte': 0.003003003003003003, 'ter': 0.003003003003003003, 'ern': 0.003003003003003003, 'rni': 0.003003003003003003, 'nim': 0.003003003003003003, 'imm': 0.003003003003003003, 'mmt': 0.003003003003003003, 'mt ': 0.003003003003003003, 't e': 0.003003003003003003, ' es': 0.003003003003003003, 'es ': 0.006006006006006006, 's i': 0.006006006006006006, ' in': 0.006006006006006006, 'n d': 0.003003003003003003, ' di': 0.006006006006006006, 'ies': 0.003003003003003003, 'ese': 0.003003003003003003, 'sem': 0.003003003003003003, 'em ': 0.003003003003003003, 'm b': 0.003003003003003003, ' bu': 0.003003003003003003, 'buc': 0.003003003003003003, 'uch': 0.003003003003003003, 'che': 0.006006006006006006, 'he,': 0.003003003003003003, 'e, ': 0.003003003003003003, ', d': 0.003003003003003003, 'e g': 0.003003003003003003, ' ge': 0.003003003003003003, 'ges': 0.003003003003003003, 'esc': 0.003003003003003003, 'sch': 0.012012012012012012, 'chi': 0.006006006006006006, 'hic': 0.006006006006006006, 'ich': 0.003003003003003003, 'cht': 0.003003003003003003, 'hte': 0.003003003003003003, 'te ': 0.003003003003003003, 'e d': 0.003003003003003003, ' de': 0.003003003003003003, 'des': 0.003003003003003003, 's k': 0.003003003003003003, ' ka': 0.003003003003003003, 'kau': 0.003003003003003003, 'aut': 0.003003003003003003, 'uts': 0.003003003003003003, 'tsc': 0.003003003003003003, 'chu': 0.003003003003003003, 'huk': 0.003003003003003003, 'uks': 0.003003003003003003, 'ks ': 0.003003003003003003, 'n m': 0.003003003003003003, ' me': 0.003003003003003003, 'men': 0.003003003003003003, 'ens': 0.006006006006006006, 'nsc': 0.006006006006006006, 'hen': 0.003003003003003003, 'ick': 0.003003003003003003, 'cks': 0.003003003003003003, 'ksa': 0.003003003003003003, 'sal': 0.003003003003003003, 'ale': 0.003003003003003003, 'len': 0.006006006006006006, 'en ': 0.003003003003003003, 'n z': 0.003003003003003003, ' zu': 0.003003003003003003, 'zu ': 0.003003003003003003, 'u e': 0.003003003003003003, ' er': 0.003003003003003003, 'erz': 0.003003003003003003, 'rzä': 0.003003003003003003, 'zäh': 0.003003003003003003, 'ähl': 0.003003003003003003, 'hle': 0.003003003003003003, 'en.': 0.003003003003003003}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXuFFkx9Xd01"
      },
      "source": [
        "We could also use a Lib:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:48.958804Z",
          "start_time": "2018-04-11T00:35:48.951804Z"
        },
        "collapsed": true,
        "id": "8hTlqoA0VDOd"
      },
      "source": [
        "import collections\n",
        "\n",
        "def buildmodel(text):\n",
        "    model = collections.Counter(xgram(text))  \n",
        "    nr_of_ngs = sum(model.values())\n",
        "\n",
        "    for w in model:\n",
        "        model[w] = float(model[w]) / float(nr_of_ngs)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:48.971804Z",
          "start_time": "2018-04-11T00:35:48.960804Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UycKWSi7VEJm",
        "outputId": "483707a2-4d0f-491a-ae60-7341bc7d9004"
      },
      "source": [
        "model = buildmodel(text)\n",
        "print(model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'e': 0.05105105105105105, ' ': 0.042042042042042045, 's': 0.03303303303303303, 'i': 0.02702702702702703, 'n': 0.02702702702702703, 'c': 0.021021021021021023, 'h': 0.021021021021021023, 'ch': 0.018018018018018018, 'u': 0.015015015015015015, 'd': 0.012012012012012012, 'r': 0.012012012012012012, 't': 0.012012012012012012, 'm': 0.012012012012012012, 'er': 0.012012012012012012, 'n ': 0.012012012012012012, 'es': 0.012012012012012012, 'sc': 0.012012012012012012, 'en': 0.012012012012012012, 'sch': 0.012012012012012012, 'a': 0.009009009009009009, 'k': 0.009009009009009009, 'di': 0.009009009009009009, 'ie': 0.009009009009009009, 'e ': 0.009009009009009009, 'in': 0.009009009009009009, 's ': 0.009009009009009009, ' d': 0.009009009009009009, 'die': 0.009009009009009009, 'in ': 0.009009009009009009, 'l': 0.006006006006006006, 'z': 0.006006006006006006, 'se': 0.006006006006006006, 'te': 0.006006006006006006, ' e': 0.006006006006006006, ' i': 0.006006006006006006, 'he': 0.006006006006006006, 'hi': 0.006006006006006006, 'ic': 0.006006006006006006, 'ks': 0.006006006006006006, 'ns': 0.006006006006006006, 'le': 0.006006006006006006, 'ie ': 0.006006006006006006, 'es ': 0.006006006006006006, 's i': 0.006006006006006006, ' in': 0.006006006006006006, ' di': 0.006006006006006006, 'che': 0.006006006006006006, 'chi': 0.006006006006006006, 'hic': 0.006006006006006006, 'ens': 0.006006006006006006, 'nsc': 0.006006006006006006, 'len': 0.006006006006006006, 'v': 0.003003003003003003, 'f': 0.003003003003003003, 'b': 0.003003003003003003, ',': 0.003003003003003003, 'g': 0.003003003003003003, 'ä': 0.003003003003003003, '.': 0.003003003003003003, ' v': 0.003003003003003003, 've': 0.003003003003003003, 'rf': 0.003003003003003003, 'fa': 0.003003003003003003, 'as': 0.003003003003003003, 'ss': 0.003003003003003003, 'ri': 0.003003003003003003, ' u': 0.003003003003003003, 'un': 0.003003003003003003, 'nt': 0.003003003003003003, 'rn': 0.003003003003003003, 'ni': 0.003003003003003003, 'im': 0.003003003003003003, 'mm': 0.003003003003003003, 'mt': 0.003003003003003003, 't ': 0.003003003003003003, 'em': 0.003003003003003003, 'm ': 0.003003003003003003, ' b': 0.003003003003003003, 'bu': 0.003003003003003003, 'uc': 0.003003003003003003, 'e,': 0.003003003003003003, ', ': 0.003003003003003003, ' g': 0.003003003003003003, 'ge': 0.003003003003003003, 'ht': 0.003003003003003003, 'de': 0.003003003003003003, ' k': 0.003003003003003003, 'ka': 0.003003003003003003, 'au': 0.003003003003003003, 'ut': 0.003003003003003003, 'ts': 0.003003003003003003, 'hu': 0.003003003003003003, 'uk': 0.003003003003003003, ' m': 0.003003003003003003, 'me': 0.003003003003003003, 'ck': 0.003003003003003003, 'sa': 0.003003003003003003, 'al': 0.003003003003003003, ' z': 0.003003003003003003, 'zu': 0.003003003003003003, 'u ': 0.003003003003003003, 'rz': 0.003003003003003003, 'zä': 0.003003003003003003, 'äh': 0.003003003003003003, 'hl': 0.003003003003003003, 'n.': 0.003003003003003003, 'e v': 0.003003003003003003, ' ve': 0.003003003003003003, 'ver': 0.003003003003003003, 'erf': 0.003003003003003003, 'rfa': 0.003003003003003003, 'fas': 0.003003003003003003, 'ass': 0.003003003003003003, 'sse': 0.003003003003003003, 'ser': 0.003003003003003003, 'eri': 0.003003003003003003, 'rin': 0.003003003003003003, 'n u': 0.003003003003003003, ' un': 0.003003003003003003, 'unt': 0.003003003003003003, 'nte': 0.003003003003003003, 'ter': 0.003003003003003003, 'ern': 0.003003003003003003, 'rni': 0.003003003003003003, 'nim': 0.003003003003003003, 'imm': 0.003003003003003003, 'mmt': 0.003003003003003003, 'mt ': 0.003003003003003003, 't e': 0.003003003003003003, ' es': 0.003003003003003003, 'n d': 0.003003003003003003, 'ies': 0.003003003003003003, 'ese': 0.003003003003003003, 'sem': 0.003003003003003003, 'em ': 0.003003003003003003, 'm b': 0.003003003003003003, ' bu': 0.003003003003003003, 'buc': 0.003003003003003003, 'uch': 0.003003003003003003, 'he,': 0.003003003003003003, 'e, ': 0.003003003003003003, ', d': 0.003003003003003003, 'e g': 0.003003003003003003, ' ge': 0.003003003003003003, 'ges': 0.003003003003003003, 'esc': 0.003003003003003003, 'ich': 0.003003003003003003, 'cht': 0.003003003003003003, 'hte': 0.003003003003003003, 'te ': 0.003003003003003003, 'e d': 0.003003003003003003, ' de': 0.003003003003003003, 'des': 0.003003003003003003, 's k': 0.003003003003003003, ' ka': 0.003003003003003003, 'kau': 0.003003003003003003, 'aut': 0.003003003003003003, 'uts': 0.003003003003003003, 'tsc': 0.003003003003003003, 'chu': 0.003003003003003003, 'huk': 0.003003003003003003, 'uks': 0.003003003003003003, 'ks ': 0.003003003003003003, 'n m': 0.003003003003003003, ' me': 0.003003003003003003, 'men': 0.003003003003003003, 'hen': 0.003003003003003003, 'ick': 0.003003003003003003, 'cks': 0.003003003003003003, 'ksa': 0.003003003003003003, 'sal': 0.003003003003003003, 'ale': 0.003003003003003003, 'en ': 0.003003003003003003, 'n z': 0.003003003003003003, ' zu': 0.003003003003003003, 'zu ': 0.003003003003003003, 'u e': 0.003003003003003003, ' er': 0.003003003003003003, 'erz': 0.003003003003003003, 'rzä': 0.003003003003003003, 'zäh': 0.003003003003003003, 'ähl': 0.003003003003003003, 'hle': 0.003003003003003003, 'en.': 0.003003003003003003})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuyvPnM7XjiM"
      },
      "source": [
        "Given a sufficient amout of text, we can get values that are typical for a language. We can use these values  to compare it with the values of an unknown text.\n",
        "\n",
        "**NLTK** offers the Declaration of Human Rights in over 300 languages. We will use those texts to build some language models, though the amount fo texts in fact is too small to get relyable models.\n",
        "\n",
        "Eventually, you have to download the NLTK ressources. This has only to be done once. If you execute the code in the next cell a dialog window will open. Select download and then the option 'book' (or 'all' or just 'udhr').\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:48.977804Z",
          "start_time": "2018-04-11T00:35:48.974804Z"
        },
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuJVagZbhQbR",
        "outputId": "64859a0e-9043-4ec3-93cf-2bda3f18fb67"
      },
      "source": [
        "import nltk\n",
        "nltk.download('udhr')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]   Package udhr is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:52.967804Z",
          "start_time": "2018-04-11T00:35:48.981804Z"
        },
        "collapsed": true,
        "id": "-m5iOlmuVGFc"
      },
      "source": [
        "from nltk.corpus import udhr\n",
        "\n",
        "#print udhr.fileids()\n",
        "\n",
        "languages = ['english','german','dutch','french','italian','spanish']\n",
        "\n",
        "english_udhr = udhr.raw('English-Latin1')\n",
        "german_udhr = udhr.raw('German_Deutsch-Latin1')\n",
        "dutch_udhr = udhr.raw('Dutch_Nederlands-Latin1')\n",
        "french_udhr = udhr.raw('French_Francais-Latin1')\n",
        "italian_udhr = udhr.raw('Italian_Italiano-Latin1')\n",
        "spanish_udhr = udhr.raw('Spanish_Espanol-Latin1')\n",
        "\n",
        "texts = {'english':english_udhr,'german':german_udhr,'dutch':dutch_udhr,'french':french_udhr,'italian':italian_udhr,'spanish':spanish_udhr}\n",
        "models = {lang:buildmodel(texts[lang]) for lang in languages}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH4UGlmpXnd9"
      },
      "source": [
        "These texts are very short and contain only a fraction of the words that belong to the vocabulary of a language. The German version is only 10 000 Characters long:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:52.974804Z",
          "start_time": "2018-04-11T00:35:52.969804Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcvKv0QZVItX",
        "outputId": "05df7832-c4e6-496e-bab3-78ce10e0b863"
      },
      "source": [
        "print(len(german_udhr))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo5e34svXooF"
      },
      "source": [
        "## 3. Determine the Language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjrYEMklXsss"
      },
      "source": [
        "We know have to compare the frequencies of the n-grams of a given text to the frequencies of a model. We will use Cosine Similarity for this:\n",
        "\n",
        "Wir müssen jetzt die n-Gram Frequenzen eiens Textes mit den Frequenzen der Modelle vergleichen. Um die Modelle zu vergleichen berechnen wir den Cosinus:\n",
        "\n",
        "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/a71c4add4abded66efd42b202c76f6a59944a587)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:52.981804Z",
          "start_time": "2018-04-11T00:35:52.976804Z"
        },
        "collapsed": true,
        "id": "9V9uWT7nVJvE"
      },
      "source": [
        "import math\n",
        "\n",
        "def cosine(a,b):\n",
        "    return sum([a[k]*b[k] for k in a if k in b]) / (math.sqrt(sum([a[k]**2 for k in a])) * math.sqrt(sum([b[k]**2 for k in b])))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:35:53.001804Z",
          "start_time": "2018-04-11T00:35:52.984804Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBFUeFXoVKw8",
        "outputId": "adda1436-5b51-4562-91e4-f227b7090da0"
      },
      "source": [
        "print(text)\n",
        "textmodel = buildmodel(text)\n",
        "for m in models:\n",
        "    print(m, cosine(models[m],textmodel))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Verfasserin unternimmt es in diesem Buche, die Geschichte des Kautschuks in Menschenschicksalen zu erzählen.\n",
            "english 0.7411160989023053\n",
            "german 0.8522092567280237\n",
            "dutch 0.7916873428505355\n",
            "french 0.7659701598838251\n",
            "italian 0.7148098723418794\n",
            "spanish 0.7444444064683035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZkeYVrgXv62"
      },
      "source": [
        "We already get decent results. Of course the accuracy could be increased if we use longer texts from a different set of genres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZvR5U_GXxFt"
      },
      "source": [
        "## 4. Beautify it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoEx_2lFX0k0"
      },
      "source": [
        "We need a function that predicts in which language a text is written in:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:36:29.310804Z",
          "start_time": "2018-04-11T00:36:29.303804Z"
        },
        "collapsed": true,
        "id": "MDOZVaHNVMAk"
      },
      "source": [
        "def guess_language(text):\n",
        "    textmodel = buildmodel(text)\n",
        "    lang = \"english\"\n",
        "    best = 0\n",
        "    for m in models:\n",
        "        c = cosine(models[m],textmodel)\n",
        "        if c > best:\n",
        "            best = c\n",
        "            lang = m\n",
        "    return lang"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:36:30.114804Z",
          "start_time": "2018-04-11T00:36:30.074804Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAg-dgYlVM7d",
        "outputId": "6649b766-176c-49cc-c094-a40234bb2bea"
      },
      "source": [
        "t = \"Wie zijn leven voltooid vindt en met een consulent in gesprek gaat over zelfdoding, stelt zelfeuthanasie vaak uit of ziet ervan af\"  \n",
        "print(guess_language(t))\n",
        "\n",
        "t = u\"L’ancien candidat écologiste à la primaire de la gauche s’était engagé à soutenir le vainqueur de ce scrutin à la fin janvier, en l’occurrence Benoît Hamon.\"  \n",
        "print(guess_language(t))\n",
        "\n",
        "\n",
        "t = \"Una capra al posto del giardiniere\"\n",
        "print(guess_language(t))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dutch\n",
            "french\n",
            "spanish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brK9km7LX22V"
      },
      "source": [
        "The last Result is wrong. Italian would be right. The text is very short and the modell is based on a too small corpus.\n",
        "\n",
        "Also, to not always calculate the models anew, we can pickle them and save them to google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:37:07.551804Z",
          "start_time": "2018-04-11T00:37:07.523804Z"
        },
        "id": "fqJgUz5cX3Ie"
      },
      "source": [
        "import pickle\n",
        "\n",
        "#from pydrive.auth import GoogleAuth\n",
        "#from pydrive.drive import GoogleDrive\n",
        "#from google.colab import auth\n",
        "#from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Save model with pickle\n",
        "pickle.dump(models, open('langidmodels.pkl', 'wb'))\n",
        "\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "#auth.authenticate_user()\n",
        "#gauth = GoogleAuth()\n",
        "#gauth.credentials = GoogleCredentials.get_application_default()\n",
        "#drive = GoogleDrive(gauth)  \n",
        "\n",
        "# get the folder id where you want to save your file\n",
        "#file = drive.CreateFile({'parents':[{u'id': folder_id}]})\n",
        "#file.SetContentFile('langidmodels.pkl')\n",
        "#file.Upload() "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-11T00:37:08.622804Z",
          "start_time": "2018-04-11T00:37:08.606804Z"
        },
        "collapsed": true,
        "id": "jW0wYcpCabql"
      },
      "source": [
        "models = pickle.load(open('langidmodels.pkl', 'rb'))"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}